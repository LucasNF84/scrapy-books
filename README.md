# üìö Scrapy Books Extraction

Este proyecto utiliza **Scrapy** para extraer informaci√≥n de libros desde [books.toscrape.com](https://books.toscrape.com). 
El scraper recorre todas las categor√≠as de libros, extrae informaci√≥n relevante, la transforma y la almacena en una base de datos **PostgreSQL**.

---

## üöÄ Tecnolog√≠as utilizadas
- **Python** üêç
- **Scrapy** (framework de web scraping)
- **PostgreSQL** (base de datos relacional)
- **Docker** (para ejecutar PostgreSQL en un contenedor)
- **dotenv** (manejo de variables de entorno)

---

## üìå Flujo del scraper
El proceso consta de **tres fases principales**: **extracci√≥n, transformaci√≥n y almacenamiento**.

### **1Ô∏è‚É£ Extracci√≥n de datos**
- Scrapy accede a la p√°gina principal de `books.toscrape.com`.
- Extrae todas las **categor√≠as** de libros desde la barra lateral izquierda.
- Para cada categor√≠a, navega por todas las p√°ginas de la misma y extrae informaci√≥n de cada libro.

### **2Ô∏è‚É£ Transformaci√≥n de datos**
Para cada libro, se procesan los siguientes campos:

| **Campo**   | **Descripci√≥n**   | **Transformaci√≥n aplicada** |
|------------|------------------|----------------------------|
| `title`    | Nombre del libro  | Se extrae directamente del HTML. |
| `price`    | Precio del libro  | Se elimina el s√≠mbolo `¬£` y se convierte a `float`. |
| `stock`    | Disponibilidad    | Se convierte en `"S√≠"` si est√° en stock, `"No"` si no. |
| `stars`    | Calificaci√≥n      | Se transforma de `star-rating Five` a `5` (n√∫mero de estrellas). |
| `category` | Categor√≠a del libro | Se extrae desde la URL de la categor√≠a. |

### **3Ô∏è‚É£ Almacenamiento de los datos**
Los datos extra√≠dos y transformados se guardan en una base de datos **PostgreSQL** en la tabla `books`.

---

## ‚öô Instalaci√≥n y configuraci√≥n

### üîπ **1. Clonar el repositorio**
```bash
git clone https://github.com/LucasNF84/scrapy-books.git
cd scrapy-books/bookProject
```

### üîπ **2. Crear y activar un entorno virtual**
```bash
python -m venv venv
source venv/bin/activate  # Para macOS/Linux
venv\Scripts\activate  # Para Windows
```

### üîπ **3. Configurar PostgreSQL con Docker**
Si no tienes PostgreSQL instalado, puedes ejecutarlo en **Docker** con:
```bash
docker run --name postgres-scrapy -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=tu_contrase√±a -e POSTGRES_DB=booksdb -p 5432:5432 -d postgres
```

### üîπ **4. Crear la tabla en PostgreSQL**
Si PostgreSQL est√° instalado localmente, crea la base de datos manualmente:
```sql
CREATE DATABASE booksdb;

CREATE TABLE books (
    id SERIAL PRIMARY KEY,
    title TEXT,
    price NUMERIC,
    stock TEXT,
    stars INTEGER,
    category TEXT
);
```

### üîπ **5. Configurar variables de entorno (`.env`)**
Crea un archivo `.env` en el directorio principal del proyecto y agrega los siguientes datos:
```ini
POSTGRES_HOST=localhost
POSTGRES_DB=booksdb
POSTGRES_USER=postgres
POSTGRES_PASSWORD=tu_contrase√±a
POSTGRES_PORT=5432
```
Para cargar estas variables en `settings.py`, instala **python-dotenv**:
```bash
pip install python-dotenv
```
Y agrega esto en `settings.py`:
```python
from dotenv import load_dotenv
import os

load_dotenv()

POSTGRES_HOST = os.getenv("POSTGRES_HOST")
POSTGRES_DB = os.getenv("POSTGRES_DB")
POSTGRES_USER = os.getenv("POSTGRES_USER")
POSTGRES_PASSWORD = os.getenv("POSTGRES_PASSWORD")
POSTGRES_PORT = int(os.getenv("POSTGRES_PORT", 5432))
```

### üîπ **6. Instalar dependencias**
Ejecuta el siguiente comando para instalar todas las librer√≠as necesarias:
```bash
pip install -r requirements.txt
```
Aseg√∫rate de que el archivo `requirements.txt` incluya:
```
scrapy
psycopg2
python-dotenv
```

### üîπ **7. Ejecutar el scraper**
Ejecuta el siguiente comando para iniciar el scraping y almacenar los datos en PostgreSQL:
```bash
scrapy crawl books
```

### üîπ **8. Verificar los datos en PostgreSQL**
Con√©ctate a la base de datos y verifica que los datos fueron insertados correctamente:
```sql
SELECT * FROM books;
```

---

## üìä Resumen de cambios recientes
‚úî Ahora los datos se almacenan en **PostgreSQL** en lugar de un archivo JSON.  
‚úî Se agreg√≥ el uso de **.env** para manejar configuraciones sensibles.  
‚úî Se cre√≥ una tabla `books` en PostgreSQL con los campos extra√≠dos del scraping.  
‚úî Se mejor√≥ el procesamiento de datos usando **ItemLoaders** en Scrapy.  
‚úî Se agreg√≥ configuraci√≥n para ejecutar PostgreSQL en **Docker**.  
‚úî Se incluy√≥ la instalaci√≥n y configuraci√≥n detallada del entorno de desarrollo.  

---

üéØ **Ahora Scrapy guarda la informaci√≥n de los libros en PostgreSQL de manera estructurada y eficiente.** üöÄ